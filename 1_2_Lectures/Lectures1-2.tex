%%!TEX TS-program = latex
\documentclass[11pt]{article} %DIF > 
\usepackage{etex}
\usepackage[utf8]{inputenc}
\input ../Auxiliary_Format_Files/PreambleNotes.tex

             
\begin{document}
\onehalfspace

\vspace*{\fill}
\begingroup
\centering

\Large {\scshape Introduction to Probability}\\

(Lectures 1-2)

\endgroup
\vspace*{\fill}

\newpage

\section{Probability Spaces and Random Variables}
The goal of Lecture 1 and Lecture 2 is twofold. First, we will present the formal definitions of a \emph{probability space} and a \emph{random variable}. Then, we will introduce some more concrete concepts that will be used throughout the course (such as  \emph{cumulative distribution function} and \emph{probability density function}). 

{\scshape Overview of Lectures 1-2:} The triplet:

$$(\Omega, \mathcal{F}, \mathbb{P}),$$

\noindent will be our notation to describe a probability space. We will call 

\begin{enumerate}
\item $\Omega$: The underlying space of uncertainty or set of states of the world. 

\item $\mathcal{F}$: The ``$\sigma$-algebra'' of subsets of $\Omega$. We will think about it is as a collection of ``events'' whose likelihood of occurrence we would like to analyze. 

\item $\mathbb{P}$: The probability measure. We will think about it as a $[0,1]$-valued function summarizing the likelihood of an event. 

\end{enumerate}

A real-valued random variable  will be denoted by the map

$$X: \Omega \rightarrow \R,$$ 

\noindent which will satisfy a restriction that we will call ``measurability''. We will focus on how the probability measure on $(\Omega, \mathcal{F})$ induces a probability over subsets of $\R$. 

Once we are done with abstract definitions, we will introduce objects that we will use quite often during this course. In the context of a real-valued random variable we will define

\begin{enumerate}[a)]
\item The cumulative distribution function (c.d.f.): which we will connect to the ``induced’’ probability measure of a random variable, 
\item ``Discrete'' and ``Absolutely Continuous'' random variables: this classification will emerge from differences in the c.d.f. of random variables. 

\item The probability density function (p.d.f.): a convenient way of summarizing the information in the c.d.f. of an absolutely continuous random variable, 

\item The expectation operator $\expec_{\mathbb{P}}[\cdot]$ (and then the variance of a real-valued random variable). 

\item Finally, the moment generating function. 

\end{enumerate}

\subsection{Measurable spaces, Probability Measures, and Probability Spaces} 

%---------------------------------Section 1:Probability Space and Independence-------------------------------

\subsubsection{$\sigma$-algebras and Measurable Spaces}
We will start with the definition of a ``measurable space''. In order to model randomness, we need to have some structure that allows us to specify what the randomness is all about. \\

Let $\Omega$ be any given nonempty set and let $\mathcal{F}$ be a nonempty collection of subsets satisfying the following properties:
\begin{enumerate}
	\item $\mathcal{F}$ is ``closed'' under complements: $F \in \mathcal{F} \implies \Omega \backslash F \in \mathcal{F}$
	\item $\mathcal{F}$ is ``closed'' under countable unions: $F_{n} \in \mathcal{F}$ for all $n \in \mathbb{N} \implies \cup_{n=1}^{\infty} F_n \in \mathcal{F}$.
\end{enumerate}

\begin{definition}[\textbf{$\sigma$-algebra}] (\cite{Billingsley95}, p. 19 and 20)
	If the nonempty collection $\mathcal{F} \subseteq 2^{\Omega}$ satisfies properties 1,2 above then $\mathcal{F}$ is called a $\sigma$-algebra (or a $\sigma$-algebra of subsets of $\Omega$)  
\end{definition}

\begin{definition}[\textbf{Measurable Space}] (\cite{Billingsley95}, p. 161)
	The pair $(\Omega, \mathcal{F})$, where $\mathcal{F}$ is a $\sigma$-algebra of subsets of $\Omega$ is called a measurable space. The subsets of $\mathcal{F}$ are called the events of $\Omega$.
\end{definition}

\noindent If you are interested in playing with these definitions, here is a simple exercise. \\

\begin{prproblem}[Optional]
Let $A$ be a collection of elements of $2^\Omega$. Define 
$$F^*(A) \equiv \{\mathcal{F} \: | \: \mathcal{F} \: \text{is a} \: \sigma\text{-algebra of } \Omega \: \text{containing} \: A\} $$

\begin{enumerate}[i)]
\item Show that $F^*(A)$ is non-empty. 
\item Let $\sigma(A)$ denote the intersection over all the $\sigma$-algebras contained in $F^*(A)$. Show that $\sigma(A)$ is a $\sigma$-algebra. The collection $\sigma(A)$ will be the called the ``$\sigma$-algebra generated by A''. Such collection is unique.
\end{enumerate}
\end{prproblem}

\begin{prproblem}[Optional] \label{prprob:closed_under_inter}
  Show that $\sigma$-algebra is ``closed'' under countable intersections. That
  is, if $F_n \in \mathcal{F}$ for all $n\in\mathbb{N}$ then $\cap_{n=1}^\infty
  F_n \in \mathcal{F}$.
\end{prproblem}

\subsubsection{Probability Measures}

Once we know which are the objects that uncertainty will refer to, we need to have a formal way of expressing the ``likelihood'' of the different events we have specified. In order to do this we will define a \emph{probability measure}. 

\begin{definition} (\textbf{Probability Measure}) (\cite{Billingsley95}, p. 22) Let $(\Omega, \mathcal{F})$ be a measurable space. Let $\mathbb{P}: \mathcal{F} \rightarrow [0,1]$ be a ``set'' function mapping the $\sigma$-algebra of subsets of $\Omega$ into the real line. We say that $\mathbb{P}$ is a probability measure if it satisfies the following properties:
\begin{enumerate}
	\item $\mathbb{P}(\emptyset)=0$, $\mathbb{P}(\Omega)=1$ [Normalization]
	\item $\mathbb{P}(\bigcup_{n=1}^{\infty} A_n)= \sum_{n=1}^{\infty} \mathbb{P}(A_n)$ for a countable disjoint sequence of elements of $\mathcal{F}$ [$\sigma$-additivity]\\
\end{enumerate}
\end{definition}


\begin{definition}[\textbf{Probability space}] (\cite{Billingsley95}, p. 23)
The triplet $(\Omega, \mathcal{F}, P)$ is called a probability space. 
\end{definition}

Some implications of the definition of a probability measure. 

\begin{enumerate}

\item \textbf{Monotonicity:} For events $A,B$, $A \subseteq B$ implies $\mathbb{P}(A) \leq \mathbb{P}(B)$.

\begin{proof}
Write $B= A \cup (B \backslash A)$. By assumption, $A\in \mathcal{F}$; Practice Problem \ref{prprob:closed_under_inter} implies $B\setminus
A \in \mathcal{F}$ because $B\setminus A = B
\cap \left( \Omega\setminus A \right)$. By definition $A \cap (B\backslash
A)=\emptyset$.  Therefore, by finite additivity (which is implied by $\sigma$-additivity) we have $\prob(B)=\prob(A) + \prob(B \backslash A)$, which implies $\prob(B)-\prob(A)= \prob(B \backslash A) \geq 0$, as $\prob$ is a $[0,1]$-valued set function.  
\end{proof}

\item \textbf{Boole's Inequality:} (\cite{Billingsley95} p. 24) Boole's inequality is a pretty useful result that will show up quite often.  Let $A_n$ be any sequence of events in $\mathcal{F}$. Then
$$\prob(\cup_{n=1}^{\infty} A_n) \leq \sum_{i=1}^{\infty} \prob(A_n)  $$

We provide a proof of Boole's inequality for only two events $A,B$. This is, we show that:

$$\prob(A \cup B) \leq \prob(A) + \prob(B) $$

\begin{proof}
Let $A_1=A$, $A_2=B \backslash A$. By finite additivity:
\begin{eqnarray*}
\prob(A \cup B) &=& \prob(A_1 \cup A_2)\\
&=& P(A_1) + P(A_2)   
\end{eqnarray*}
Since $B \backslash A \subseteq B$, then $\prob(B\backslash A) \leq P(B)$. Therefore, $\prob(A \cup B) \leq P(A) + P(B)$. 
\end{proof}

\end{enumerate}

In order for you to manipulate the definition of a probability measure, you will be asked to write down proofs of the following statements:\\

\noindent\begin{prproblem}[Properties of a probability measure] Let $(\Omega, \mathcal{F}, \prob)$ be a probability space. Show that a probability measure satisfies:
\begin{enumerate}
\item $\prob(F_1 \cup F_2) = \prob(F_1) + \prob(F_2) - \prob(F_1 \cap F_2)$ \text{for any } $F_1,F_2 \in \mathcal{F}$
\item $\prob(\cup_{n \in \mathbb{N}} F_n) \leq \sum_{n \in \mathbb{N}} \prob(F_n) $ for any countable collection $\{F_n\}$
\end{enumerate}
\end{prproblem}

%\noindent \textbf{Comment:} [Sierpinski Class Lemma or Dynkin's $\pi$-$\lambda$ theorem]: Note that we have defined a probability measure as a set-valued function mapping elements in the $\sigma$-algebra $\mathcal{F}$ into the $[0,1]$ interval. Often times, it will be desirable to characterize the probability measure by the values that it takes in a smaller subclass of sets. One interesting result, which follows Sierpinski’s Class Lemma (pg. 34, Chapter B, Efe's book in Probability Theory), is the following:
%
%\begin{result} 
%Let $\mathcal{A}$ be a collection of sets satisfying: 
%$$a,a' \in \mathcal{A} \implies a \cap a' \in \mathcal{A} $$
%Suppose that $\prob_1$, $\prob_2$ are two probability measures with domain $\sigma(\mathcal{A})$ such that:
%$$\prob_1(a) = \prob_2(a) \quad \forall \: a\in \mathcal{A}.$$
%\noindent Then $\prob_1(a)=\prob_2(a)$ for every $a \in \sigma(\mathcal{A}).$
%\end{result}  

\subsection{Random Variables}

Along with a probability measure, a central concept in probability and statistics is that of a \emph{random variable}.

\begin{definition}[S-valued random variable]
Let $(\Omega, \mathcal{F})$, $(S, \mathcal{S})$ be two measurable spaces. The map:
$$X: \Omega \rightarrow S$$
\noindent is called an S-valued random variable [relative to $(\Omega, \mathcal{F})$-$(S, \mathcal{S})$] if for all $A \in \mathcal{S}$  :
$$X^{-1}(A) \equiv \{\omega \in \Omega \: | \: X(\omega) \in A\} \in \mathcal{F},$$
\noindent this is, if $X^{-1}(A)$ is \emph{measurable} for all $A \in \mathcal{S}$.   
\end{definition} 

Note that, by definition, a random variable takes events in the space $S$ to well-defined events in the space $\Omega$. If there is already a well-defined probability measure $\prob$ on $(\Omega, \mathcal{F})$, then there is a natural ``induced’’ probability measure in $(S, \mathcal{S})$:

\begin{definition}[``Induced’’ Probability Measure or ``Law’’ of a Random Variable] (see \cite{Billingsley95} p. 185 on Transformation of measures and see if you can make the connection) Let $(\Omega, \mathcal{F}, \prob)$ be a probability space. The probability measure over $(S, \mathcal{S})$ induced by the random variable $X: \Omega \rightarrow S$ is given by:

$$P_{X}(A) \equiv \prob(X^{-1}(A)) \quad \forall \: A \in \mathcal{S}.$$

\end{definition}



\subsubsection{Cumulative Distribution Function for an $\R$-valued random variable}

In this section, we will analyze the statement: ``X is a real-valued random variable with a \emph{cumulative distribution function} $F:\R \rightarrow [0,1]$''. We will explain the relation between the c.d.f. of a random variable and the induced probability measure we discussed in the last subsection. We will focus on real-valued random variables (relative to the Borel $\sigma$-algebra on the real line, which is the smallest $\sigma$-algebra containing all open sets). 

\begin{definition} (\cite{Billingsley95}, p. 188 and 256)
The cumulative distribution function (c.d.f.) of a real-valued random variable $X: \Omega \rightarrow \R$ is defined as the real-valued function $F:\R\rightarrow[0,1]$ given by
$$F_{X}(x) \equiv \prob\{ \omega \in \Omega \: | \: X(\omega) \leq x\} = \prob\{X^{-1}(-\infty,a]\}    $$
\end{definition}

The c.d.f. of a random variable $X$ is nothing else than its induced probability measure evaluated at sets of the form $(-\infty, a]$. The c.d.f. satisfies the following properties:

\begin{proposition} If $F_{X}$ is the c.d.f. of a random variable $X: \Omega \rightarrow \R$ then 
\begin{enumerate}
\item $F_{X}$ is non-decreasing.
\item $\lim_{x \uparrow \infty} F_{X}(x)=1$
\item $\lim_{x \downarrow -\infty} F_{X}(x)=0$
\item $\lim_{h \rightarrow 0^{+}} F(x+h)=F(x)$
\end{enumerate}

\noindent Furthermore, if $F$ is a function satisfying 1,2,3,4, then there is a probability space $(\Omega, \mathcal{F}, \prob)$ and a random variable $X: \Omega \rightarrow \R$ such that $F$ coincides with $F_{X}$. 

\end{proposition}

\noindent \begin{prproblem}
   This week's problem set will walk you through the proof of Proposition 1.\\ 
\end{prproblem}

Here are some commonly used examples of c.d.f.s of real-valued random variables:

\begin{itemize}
\item \emph{Uniform Distribution}: The random variable $X$ is said to have a uniform distribution in $[a,b]$ if the c.d.f. is given by:
\begin{equation*}
F(x) = 
\left\{
\begin{array}{ccc}
0  & \text{if}  & x < a   \\
x-a/[b-a]  & \text{if}  & x \in [a,b)   \\
1 & \text{if}  & x \geq b
\end{array}
\right.
\end{equation*}

\item \emph{Bernoulli Distribution}: The random variable $X$ is said to have a Bernoulli distribution with parameter $p \in [0,1]$ if its c.d.f. is given by:

\begin{equation*}
F(x) = 
\left\{
\begin{array}{ccc}
0  & \text{if}  & x < 0   \\
1-p  & \text{if}  & x \in [0,1)   \\
1 & \text{if}  & x \geq 1
\end{array}
\right.
\end{equation*}

\item \emph{Geometric Distribution}: The random variable $X$ is said to have a Geometric Distribution with parameter $p$ if its c.d.f. is given by:

\begin{equation*}
F(x) = 
\left\{
\begin{array}{ccc}
0  & \text{if}  & x < 1   \\
1-(1-p)^{k}  & \text{if}  & x \in [k,k+1) \text{ for } k \in \mathbb{N} \\
\end{array}
\right.
\end{equation*}


\item \emph{Exponential Distribution}: The random variable $X$ is said to have an exponential distribution with parameter $\lambda$>0 if

\begin{equation*}
F(x) = 
\left\{
\begin{array}{ccc}
0  & \text{if}  & x < 0   \\
1-e^{-\lambda x}  & \text{if}  & x \geq 0   \\
\end{array}
\right.
\end{equation*}

\item \emph{Gaussian Distribution:} The random variable $X$ is said to have a Gaussian distribution with parameters $(\mu, \sigma^2)$ if 

$$F(x) = \int_{-\infty}^{x} \frac{1}{\sqrt{2 \pi \sigma^2} } \exp\Big(-\frac{1}{2 \sigma^2} (u-\mu)^2 \Big) du $$ 

\item \emph{Pareto Distribution:} The random variable $X$ is said to have a Pareto distribution with parameters $(x_m, \alpha)$ if 

\begin{equation*}
F(x) = 
\left\{
\begin{array}{ccc}
0  & \text{if}  & x < x_m   \\
1-\Big(\frac{x_m}{x} \Big)^{\alpha} & \text{if}  & x \geq x_m   \\
\end{array}
\right.
\end{equation*}

\end{itemize}

One common way to classify the random variables and their c.d.f.s is the following:

\begin{definition}[Simple, Discrete, Continuous, and Absolutely Continuous Random Variables]  \:\
\begin{enumerate}
\item \textbf{Simple Random Variables:} A random variable $X$ is simple if there
  is a finite set $\{x_1, \ldots x_k\}$, $x_1<x_2< \ldots < x_k$ such that 
$$\prob_{X}(\{x_1, \ldots x_k\}^c)=0$$
\item \textbf{Discrete Random Variables:} A random variable $X$ is discrete if there is a countable set $\{x_1, x_2, \ldots\}$, $x_1<x_2<\ldots$ such that 
$$\prob_{X}(\{x_1, x_2\ldots \}^c)=0$$
The smallest set $\{x_1, x_2, \ldots\}$ for which $\prob_{X}(\{x_1, x_2\ldots \}^c)=0$ is called the support of $X$. The map $p: \text{Supp} \rightarrow [0,1]$ defined by $p(s)\equiv\prob_{X}(s)$ is called the probability mass function. 
\item \textbf{Continuous Random Variables:} A random variable $X$ is continuous if the c.d.f. of $X$ is a continuous function.
\item \textbf{Absolutely Continuous Random Variables (w.r.t. Lebesgue Measure):} A random variable $X$ is absolutely continuous if:
$$F(x) = \int_{-\infty}^{x} f(y)dy $$
for some integrable, nonnegative function $f$ that we will call the \textbf{probability density function} (p.d.f.) of $X$. If $F$ is continuously differentiable the p.d.f. will coincide with the derivative of $F$ (see p. 257 in \cite{Billingsley95}).
\end{enumerate}

\end{definition}

A Bernoulli r.v. is an example of a simple distribution. A Geometric r.v. is an example of a discrete random variable. The gaussian, pareto, and exponential distribution are both continuous and absolutely continuous random variables. Note that not every random variable falls into one of the categories above (see, for example, the entry for Cantor's function in wikipedia) .

\subsubsection{Moments of Discrete and Absolutely Continuous Random Variables}
In this section we introduce the definition of expectation for only discrete and absolutely continuous random variables. For a more detailed exposition you can see Chapters 1.4-1.6 in \cite{durrett2010}.

\begin{definition}[Expectation of the transformation of an absolutely continuous random variable] Let $X$ be an absolutely continuous real-valued random variable with c.d.f $F$ and p.d.f. $f(x)$. Let $g:X \rightarrow \R$ be a real-valued function. The expectation of $g(X)$ under $F$ is defined as:

$$\expec_{F}[g(X)] \equiv \int_{\R} g(x)f(x)dx  $$



\end{definition}
 
 \begin{definition}[Expectation of the transformation of a discrete random variable] Let $\{x_1, x_2, \ldots\}$ be the support of the discrete random variable $X$. Let $g:X \rightarrow \R$ be a real-valued function. The expectation of $g(X)$ under the probability mass function $p$ is given by:
 $$\expec_{F}[g(X)] \equiv \sum_{x_i \in \text{Supp}} g(x_i) p(x_i).   $$
 \noindent  
 \end{definition}
 
 \noindent Now, some important observations:
 
 \begin{enumerate}
 \item \textbf{Mean of a random variable:} $E_{F}[X] \equiv \mu$ is called the \emph{mean} or \emph{first moment} of $X$. If $E_{f}[|X|]< \infty$ then $X$ is said to be integrable.
 \item \textbf{Variance of a random variable:} $E_{F}[ (X-\mu)^2 ]\equiv \sigma^2$ is called the \emph{variance} or \emph{second centered moment} of $X$. The mean and the variance of random variables will play an important role in Weak Laws of Large numbers and Central Limit Theorems. For certain random variables the variance need not be finite (the pareto distribution with parameter $\alpha=2$ is an example of this fact)
 \item \textbf{Jensen's Inequality:} For any convex function $g$: $\expec_{F}[g(X)] \geq g(\expec[X])$. This is an important result. We will not prove it, but we will be using it quite often.  
 \item \textbf{Markov's Inequality:} For any random variable $X$ and $c>0$, $c\prob_{X}[|X|>c] \leq \expec_{F}[|X|]$  
 \item \textbf{k-th Moment:} $E_{F}[X^{k}]$ is called the $k$-th uncentered moment of the random variable $X$, $k=1,2, \ldots$. Note that Jensen's inequality implies that if $E_{F}[|X|^{k}]<\infty$ for some $k \in \mathbb{N}$ then $E_{F}[|X|^{j}]<\infty$ for all $j<k$. Likewise, if $E_{F}[|X|^{k}]=\infty$, then $E_{F}[|X|^{j}]=\infty$ for all $j>k$. 
 
  \item \textbf{Layer Representation of k-th moments:} if $X$ is an absolutely continuous random variable and $\expec[|X|^{k}]<\infty$ then $\expec[|X|^{k}]=k\int_{0}^{\infty}c^{k-1}\prob_{X}(|x|>c)dc$.
 
  \item \textbf{Moment Generating Function:} The random variable $X$ is said to have a moment generating function $m_{X}(t)$ if 
 $$m_{X}(t) \equiv \expec_{F}[\exp(tX)]<\infty \quad \text{for all } t \in (-\epsilon, \epsilon)$$
 \noindent for some $\epsilon>0$. {\scshape Important}: Two random variables with the same moment generating function have the same distribution. 
\end{enumerate}

\noindent The last question of this week's problem set will ask you to go over some of these concepts. 

\newpage

\noindent \textbf{Quick Summary of Lectures 1 and 2:} We have provided formal definitions of a probability space and a real-valued random variable. 

We defined discrete and absolutely continuous random variables. We used our classification to provide a definition of the expectation of a function $g(X)$. We defined the mean of a real-valued random variable ($\mu$), the variance of a real-valued random variable ($\sigma^2$), the $k$-th moment of a real-valued random variable, and at the very end of Lecture 2, the \emph{moment generating function}. 

The moment generating function contains---in a sense that we did not make precise---the same information as the c.d.f. of a real-valued random variable. Here are some results to keep in mind. 

\begin{itemize}
\item Two discrete random variables with the same moment generating function have the same support and the same probability mass function. See \cite{Billingsley95}, p.147, second paragraph.
\item Two positive random variables with the same moment generating function have the same distribution. See \cite{Billingsley95}, Theorem 22.2. Can you fill in the details of the proof? 
\end{itemize}

\noindent {\scshape Optional:} Suppose that $F_{X}$ has a density $f$. Suppose that $m_{X}(t)=\expec[\exp(tX)]$ is well defined for every $t \in \R$. The question is: how do we recover $f$ from the moment generating function? An sketch of the answer is the following:

\begin{enumerate}
\item Extend the image of the m.g.f. to the \emph{complex} plane: Let $i=\sqrt{-1}$. For $t \in \R$, define:
$$\phi(t)\equiv m_{X}(it)=\expec[\exp(itX)] $$ 
\noindent The function $\phi(t):\R \rightarrow \mathbb{C}$ is called the \emph{characteristic function} (in fact, this is always well defined: even if the m.g.f. does not exist.).
\item Recover the p.d.f. from the characteristic function: It turns out that one can prove the following equality (\emph{or inversion formula}):
$$f(x) = \int_{-\infty}^{\infty} \exp(-it) \phi(t) dt $$
\end{enumerate}

You can found details in Section 26 (342-349) in \cite{Billingsley95} or Section 3.3 (106-111) in \cite{durrett2010}. The main take away (and we will use this result later) is that under certain conditions two random variables with the same moment generating function have the same distribution over the Borel $\sigma$-algebra in the real line. In this sense, the moment generating function provides a characterization of the c.d.f.  

\newpage

\bibliographystyle{../Auxiliary_Format_Files/ecta}
\bibliography{../Auxiliary_Format_Files/BibMaster}

\end{document}
%--------------------------------------------------------------------------------------------------------------------------------%
%--------------------------------------------------------------------------------------------------------------------------------%




 
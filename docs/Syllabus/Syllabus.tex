\documentclass[11pt]{article} 
\usepackage{etex}
\input{../AuxFiles/PreambleNotes.tex}

\title {Econometrics I\thanks{First version: August 26th, 2013. This version: \today} }
\author {Jos\'e Luis Montiel Olea \protect\\
Fall 2021
}
\date{}
             
\begin{document}
\onehalfspace
\maketitle


\noindent \textbf{Course Description:} This course (September 13th-October 20th) will provide a graduate-level introduction to probability and statistics for economists.\\ 

\noindent \textbf{Prerequisite(s):} My main assumption is that you have been exposed to at least one proof-based course in economics or mathematics. Previous undergraduate work in probability and statistics is neither assumed nor required. \\ 

\noindent \textbf{Background:} Familiarity with the following concepts would be helpful: sequences of real numbers, convergence of a sequence of real numbers, continuity of $\R^m$-valued functions, integration. \\

\noindent \textbf{Text(s):} The lectures will be based on a set of notes and slides posted online. Occasionally, the following references will be cited:

\begin{enumerate}[a)]
\item ``\emph{Probability: Theory and Examples}'' by Rick Durret [2010]. Cambridge University Press. Fourth Edition
\item ``\emph{Testing Statistical Hypothesis}'' by Lehmann, E.L. and Romano, J.P. [2005]. Springer Verlag
\item ``\emph{Probability Theory with Economic Applications}'' by Efe Ok. \href{https://files.nyu.edu/eo1/public/books.html}{Available online}.
\item ``\emph{Introduction to Mathematical Statistics}'' by Hogg, Robert V. and Mckean, Joseph W. and Allen, Craig D. [2006] Pearson Education India. 
\item ``\emph{Real analysis and Probability}'' by Dudley, Richard [2002]. Cambridge University Press. 
\item ``\emph{Probability and Measure}'' by Billingsley, Patrick [1995]. John Wiley \& Sons. 
\item ``\emph{Introduction to Mathematical Statistics: a Decision Theoretic Approach}'' by Ferguson, Thomas [1967]. Academic Press New York
\end{enumerate}
\noindent These are optional references that you can find helpful during the course.  \\

\noindent \textbf{Problem Sets:} There will be 5 problem sets. The first problem set will carry a total weight of 5\% of the final grade; the second problem set, 10\%, and the last three problem sets 20\% each. This means that the problem sets are important, as they represent 75\% of the final grade. \\ 

\noindent \textbf{Exam:} There will be a take-home midterm examination scheduled for Sunday, October 24th. I have typically given students 3-4 hours to complete the exam, but the average time for completion has been 2.5 hours. \\

\noindent \textbf{Lecture Notes:} The lecture notes were intended to provide a thorough explanation of the materials covered in class (plus, some additional topics that you may find interesting). I do not expect you master materials in the notes that were not covered in lecture (unless I ask you to do so). My hope is that the material covered in class is enough for you to do the problem sets. The lecture notes should be viewed as your primary reference to understand things that were not quite clear from the discussion in lecture. 
\newpage

\textbf{Course Outline (Tentative)}

\begin{enumerate}
\item {\scshape Probability Theory} (4 lectures/2 weeks)
\begin{itemize}
\item \emph{Lecture 1-2}: Probability Spaces, Real-valued Random Variables, Cumulative Distribution Functions (c.d.f.),  Probability Density Functions (p.d.f.), Moments of Random Variables, Mean and Variance, Moment Generating Function. \\

{\scshape Appendix:} If I have time, I will give have a very quick discussion concerning \emph{distance between probability measures}. \\

\item \emph{Lecture 3-4} Multivariate Distributions, Moments of Random Vectors, Independence of Random Variables and some useful characterizations, Conditional Probability and Conditional Expectation.  \\

{\scshape Appendix:} Kolmogorov\textquoteright s definition of Independence. \\
\end{itemize}
\item {\scshape Mathematical Statistics} (8 lectures/4 weeks) (This is my favorite part!)
\begin{itemize}
\item \emph{Lecture 5-6:} Definition of a Statistical Model (I will also talk about identification, statistical sufficiency, and I will introduce the Normal Linear Regression Model as a running example). Definition of a Statistical Problem (general framework to talk about estimation, hypothesis testing, and inference). Elements of a finite-sample statistical decision problem: loss function, Risk, and decision rules. Bayes rules and minimax rules.   \\

\item \emph{Lecture 7-8:} Prediction and Point estimation. Definition of Maximum Likelihood (ML) Estimators and Bayesian Estimators.  Derivation of ML and Bayes estimators for the Normal Linear Regression model (Ordinary Least Squares and Ridge).  Mean squared error optimality of OLS among unbiased estimators. Cramer-Rao lower bound. Comments regarding some suboptimality results for the OLS estimator (James-Stein/Empirical Bayes estimators). \\

\item \emph{Lecture 9-10:} Testing. Null hypothesis and alternative hypothesis. Score Test, Likelihood Ratio Test, Wald tests, and Bayes Tests. Finite-sample properties of statistical tests (rate of Type I/Type II error). Neyman-Pearson Lemma and the optimality of the Likelihood Ratio Test. Testing Problems with a nuisance parameter. \\

\item \emph{Lecture 11-12:} Confidence sets and credible sets. (Parametric) Bootstrap confidence intervals and Bayesian equal-tailed credible intervals. Finite-sample properties of confidence/credible sets. Constructing confidence sets via test-inversion. Confidence bands. 

\end{itemize}

\end{enumerate}

%\bibliographystyle{../AuxFiles/ecta}
%\bibliography{../AuxFiles/BibMaster}

\end{document}





 
 